{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage import io, transform\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torch.utils.data import Dataset, SubsetRandomSampler, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = \"your_path_to_train_folder\"\n",
    "test_folder = \"your_path_to_test_folder\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create custom class to prepare data for DataLoader\n",
    "class CatOrDog(Dataset):\n",
    "    def __init__(self, folder, transform=None):\n",
    "        self.transform = transform\n",
    "        self.folder = folder\n",
    "        \n",
    "    def __len__(self):\n",
    "        count = 0\n",
    "        for filename in os.listdir(self.folder):\n",
    "            count+=1\n",
    "        return count\n",
    "    \n",
    "    def __getitem__(self, index):        \n",
    "\n",
    "        if torch.is_tensor(index):\n",
    "            index = idx.tolist()\n",
    "        \n",
    "        path = os.path.join(self.folder, os.listdir(self.folder)[index])\n",
    "\n",
    "        images_name = os.listdir(self.folder)\n",
    "        img_name = images_name[index]\n",
    "        image = io.imread(path)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = transforms.functional.to_pil_image(image)\n",
    "            image = self.transform(image)\n",
    "            image = np.asarray(image)\n",
    "\n",
    "        if ('cat' in img_name):\n",
    "            y = 0\n",
    "            y = torch.tensor(y, dtype=torch.long)\n",
    "        else:\n",
    "            y = 1\n",
    "            y = torch.tensor(y, dtype=torch.long)\n",
    "        \n",
    "        return (image, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CatOrDog(train_folder, \n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.Resize((224, 224)),\n",
    "                           transforms.ToTensor(),\n",
    "                           # Use mean and std for pretrained models\n",
    "                           # https://pytorch.org/docs/stable/torchvision/models.html\n",
    "                           transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])                         \n",
    "                       ])\n",
    "                      )\n",
    "test_dataset = CatOrDog(test_folder, \n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.Resize((224, 224)),\n",
    "                           transforms.ToTensor(),\n",
    "                           # Use mean and std for pretrained models\n",
    "                           # https://pytorch.org/docs/stable/torchvision/models.html\n",
    "                           transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])                         \n",
    "                       ])\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "data_size = len(train_dataset)\n",
    "validation_fraction = .2\n",
    "#split data on train and validation part\n",
    "val_split = int(np.floor((validation_fraction) * data_size))\n",
    "indices = list(range(data_size))\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "val_indices, train_indices = indices[:val_split], indices[val_split:]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                           sampler=train_sampler)\n",
    "val_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                         sampler=val_sampler)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, loss, optimizer, num_epochs):\n",
    "    \"\"\"\n",
    "    The main function for the training model.\n",
    "    \n",
    "    Returns: history of training    \n",
    "    \"\"\"\n",
    "    loss_history = []\n",
    "    train_history = []\n",
    "    val_history = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        \n",
    "        loss_accum = 0\n",
    "        correct_samples = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        for i_step, (x, y) in enumerate(train_loader):\n",
    "             \n",
    "            x_gpu = x.to(device)\n",
    "            y_gpu = y.to(device)\n",
    "            prediction = model(x_gpu)    \n",
    "            loss_value = loss(prediction, y_gpu)\n",
    "            optimizer.zero_grad()\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, indices = torch.max(prediction, 1)\n",
    "            correct_samples += torch.sum(indices == y_gpu)\n",
    "            total_samples += y.shape[0]\n",
    "            \n",
    "            loss_accum += loss_value\n",
    "\n",
    "        ave_loss = loss_accum / i_step\n",
    "        train_accuracy = float(correct_samples) / total_samples\n",
    "        val_accuracy = compute_accuracy(model, val_loader)\n",
    "        \n",
    "        loss_history.append(float(ave_loss))\n",
    "        train_history.append(train_accuracy)\n",
    "        val_history.append(val_accuracy)\n",
    "        \n",
    "        print(\"Average loss: %f, Train accuracy: %f, Val accuracy: %f\" % (ave_loss, train_accuracy, val_accuracy))\n",
    "        \n",
    "    return loss_history, train_history, val_history\n",
    "        \n",
    "def compute_accuracy(model, loader):\n",
    "    \"\"\"\n",
    "    Computes accuracy on the validation part of the dataset\n",
    "    \n",
    "    Returns: accuracy as a float value between 0 and 1\n",
    "    \"\"\"\n",
    "    model.eval() \n",
    "    \n",
    "    correct_samples = 0\n",
    "    total_samples = 0\n",
    "    for i_step, (x, y) in enumerate(val_loader):\n",
    "            x_gpu = x.to(device)\n",
    "            y_gpu = y.to(device)\n",
    "            prediction = model(x_gpu)      \n",
    "            _, indices = torch.max(prediction, 1)\n",
    "            correct_samples += torch.sum(indices == y_gpu)\n",
    "            total_samples += y.shape[0]\n",
    "    val_accuracy = float(correct_samples) / total_samples\n",
    "    return val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the pretrained model and reset final layer\n",
    "model = models.resnet18(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 0.577004, Train accuracy: 0.730673, Val accuracy: 0.945000\n",
      "Average loss: 0.193776, Train accuracy: 0.960100, Val accuracy: 0.975000\n",
      "Average loss: 0.094560, Train accuracy: 0.978803, Val accuracy: 0.970000\n",
      "Average loss: 0.058930, Train accuracy: 0.990025, Val accuracy: 0.970000\n",
      "Average loss: 0.046579, Train accuracy: 0.996259, Val accuracy: 0.980000\n"
     ]
    }
   ],
   "source": [
    "parameters = model.parameters()\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(parameters, lr=0.001, momentum=0.9)\n",
    "\n",
    "loss_history, train_history, val_history = train_model(model, train_loader, val_loader, loss, optimizer, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader):\n",
    "    \"\"\"\n",
    "    Checks the model on the test data\n",
    "    \n",
    "    Returns: list with predicted values 'cat' or 'dog'\n",
    "    \"\"\"\n",
    "    output = []     \n",
    "    model.eval() \n",
    "    \n",
    "    for i_step, (x, _) in enumerate(test_loader):\n",
    "        x_gpu = x.to(device)\n",
    "        prediction = model(x_gpu)\n",
    "    for i in range(len(prediction)):\n",
    "        out = prediction[i].cpu().data.numpy().argmax()\n",
    "        if out == 0:\n",
    "            output.append('cat')\n",
    "        else:\n",
    "            output.append('dog')\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dog', 'dog', 'cat', 'dog', 'cat', 'dog', 'cat', 'cat', 'cat', 'cat']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have good validation accuracy and correct prediction on test data, let's save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"your_path_to_work_folder\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
